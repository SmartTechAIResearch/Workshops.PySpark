{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> PySpark labo </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN MET HET INVULLEN VAN JE NAAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens dit deel van het labo zal je de PySpark basics leren en hoe ze toe te passen voor machine learning.  \n",
    "De dataset waarmee gewerkt zal worden is een dataset over huizen en op het einde zal je de prijs van een huis proberen te voorspellen aan de hand van lineaire regressie.  \n",
    "De kolommen die aanwezig zijn in de dataset en hun beschrijving zijn:\n",
    "\n",
    "`OverallQual`: Overall material and finish quality  \n",
    "`YearBuilt`: Original construction date  \n",
    "`YearRemodeled`: Remodel date  \n",
    "`basement_SF`: Total square feet of basement area  \n",
    "`1stFloor_SF`: First Floor square feet  \n",
    "`2ndFloor_SF`: Second floor square feet  \n",
    "`LivingArea_SF`: Above grade (ground) living area square feet  \n",
    "`FullBath`: Full bathrooms above grade  \n",
    "`Bedrooms`: Bedrooms above grade (does NOT include basement bedrooms)  \n",
    "`TotalRooms`: Total rooms above grade (does not include bathrooms)  \n",
    "`Fireplaces`: Number of fireplaces  \n",
    "`GarageCars`: Size of garage in car capacity  \n",
    "`GarageArea_SF`: Size of garage in square feet  \n",
    "`WoodDeck_SF`: Wood deck area in square feet  \n",
    "`OpenPorch_SF`: Open porch area in square feet  \n",
    "`SalePrice`:the property's sale price in dollars. This is the target variable that you're trying to predict.  \n",
    "De te beantwoorden vragen/opdrachten staan altijd in italics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> SparkSession, data inlezen en data weergeven</span>\n",
    "Een SparkSession voorziet een single point of entry om te interageren met de onderliggende Spark functionaliteit en laat de gebruiker toe om te programmeren met de DataFrame API.  \n",
    "De te gebruiken functie om een sparksessie te bouwen is:  \n",
    "`spark = SparkSession.builder.appName('name').getOrCreate()`  \n",
    "*Bouw nu zelf een SparkSession met de naam labo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data kan ingelezen worden met de functie: `spark.read.csv('myfile')`  \n",
    "*Laad de data `house_prices.csv` in en zet de parameters `inferSchema` en `header` op True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De functie `df.printSchema()` toont alle kolommen en het type waarden dat hierin aanwezig zijn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wat is het type waarden aanwezig in de kolom basement_SF?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om een spark DataFrame (of spark column) weer te geven moet je de functie `df.show()` aanroepen. Dus telkens een functie een Spark Dataframe returned moet je `.show()` gebruiken om het resultaat te kunnen zien.  \n",
    "*Bekijk nu zelf de data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de namen van de kolom weer te geven als lijst kan je de functie:  \n",
    "`df.columns` gebruiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> selecteren van kolommen </span>\n",
    "Je kan een kolom selecteren aan de hand van de methode:  \n",
    "`df[\"column_name\"]`  \n",
    "Selecteer de kolom Fireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het verkregen type is een Column, maar met de functie `df.select('column_name')` returned een spark DataFrame, die veelzijdiger is dan het type Column.  \n",
    "*Selecteer opnieuw de kolom Fireplaces maar nu als dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de inhoud van de geselecteerde dataframe weer te geven moet je de methode `.show` aanroepen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.head(n)` geeft de eerste n rijen terug als lijst.  \n",
    "Print de eerste 5 rijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan met `df.head()` ook een specifieke rij of een bepaalde waarde selecteren met behulp van:  \n",
    "`df.head(n)[row_number][column_number]`  \n",
    "*1) Selecteer de 4de rij*  \n",
    "*2) Selecteer prijs op de 3de rij*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is dit een action of transformation?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Een nieuwe kolom aanmaken en een kolom verwijderen\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan een nieuwe kolom aanmaken met de functie: `df.withColumn('new_column_name',df[\"column\"])`  \n",
    "df[\"column\"] kan ook bewerkt worden bv: `df.withColumn('new_column_name',df[\"column\"]/2)`  \n",
    "Een kolom kan verwijderd worden met `df.drop('column')`  \n",
    "_Verander nu alle sqft kolommen naar m<sup>2</sup> (*0.0929) en verwijder de sqft kolommen. (hint: je kan ook een for-loop gebruiken)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is dit een action of transformation?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Filtering and grouping data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> Filtering Data </span>\n",
    "\n",
    "Voor het werken met big data is het belangrijk dat je snel je data kan filteren gebaseerd op bepaalde condities.  \n",
    "\n",
    "Je kunt de dataset filteren met behulp van de methode:  \n",
    "`df.filter(df[\"column_name\"] < condition)`  \n",
    "Je kan ook filteren voor meerdere condities met behulp van `|` of `&`\n",
    "\n",
    "*Filter de dataset voor huizen die gebouwd zijn na het jaar 2000, sla dit op onder de variabele `data_2000`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is dit een action of een transformation?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de `.count()` methode kan je het aantal gefilterde huizen opvragen.  \n",
    "*Hoeveel huizen bevat `dataset_2000` met minimum 2 `fireplaces` en met een `OverallQual` groter dan 5?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is dit een action of een transformation?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> GroupBy en Aggregate Functions </span>\n",
    "\n",
    "De `groupBy('column_name')` functie laat je rijen groeperen gebaseerd op een bepaalde kolom, bijvoorbeeld je kan huizen groeperen volgens bouwjaar.  \n",
    "Eenmaal je de rijen gegroepeerd hebt, kan je meerdere rijen van data aggregeren tot een output, bijvoorbeeld door het nemen van de som van alle inputrijen of de minimum waarde.  \n",
    "*Gebruik de groupBy functie op de `FullBath` kolom en vraag de minimum waarde op met de `.min()` functie.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Groepeer de rijen volgens de `GarageCars` kolom en aggregeer volgens het gemiddelde.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niet alle methoden hebben nood aan een groupby call. In plaats darvan kan je de algemene agg() methode oproepen. \n",
    "Dit kan alle rijen in de dataframe aggregeren in een kolom.  \n",
    "`df.agg({'column_name':'operation'})` de operation kan mean,min,max,count en sum zijn.\n",
    "\n",
    "*Gebruik de algemene agg() methode om de gemiddelde prijs te vinden*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze functie geeft echter een DataFrame terug, wat niet zo handig is bv. als je het gemiddelde nodig hebt om berekeningen uit te voeren. Om enkel het getal terug te krijgen moet je het getal als volgt uit de spark DataFrame halen:  \n",
    "`.collect()[row_number][column_number]`  \n",
    "*Zorg ervoor dat de algemene agg() methode het gemiddelde als getal terug geeft.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Groepeer eerst alle rijen volgens `YearRemodeled` en sla dit op als de variabele `grouped`. \n",
    "Gebruik vervolgens de algemene agg() methode om de maximale prijs te vinden per jaar*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:hotpink\"> Samenvattende oefening </span>\n",
    "*wat is de gemiddelde prijs per bouwjaar van huizen die gerenoveerd zijn na 2005, die minimum 3 slaapkamers hebben, die een 1stFloor_m2 groter dan 100 hebben en die een OverallQual boven 5 hebben?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Leg met je eigen woorden uit wat het is verschil tussen de `agg()` en de `groupBy()` functie?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Machine learning met PySpark </span>\n",
    "\n",
    "Om machine learning te kunnen toepassen met MlLib verwacht spark een format dat 2 kolommen bevat met de namen: \"label\" en \"features\".  \n",
    "De label kolom moet een numerische label bevatten, dit kan een numerische waarde zijn voor regressie of classificatie.  \n",
    "De feature kolom moet een vector van alle features bevatten.  \n",
    "In deze sectie zal je een dataframe omzetten naar het verwachte format en zal je de huisprijzen proberen te voorspellen met lineaire regressie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Prepping the data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de data correct voor te bereiden moeten alle features in een kolom onder de vorm van een vector aanwezig zijn.\n",
    "Dit kan bereikt worden met de functies: `assembler = VectorAssembler(inputCols=[list_of_column_names],outputCol='features')`  \n",
    "`new_dataframe = assembler.transform(df)`  \n",
    "*Maak een lijst met alle kolomnamen die gebruikt kunnen worden als features en transformeer ze met de VectorAssembler.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Splitsen in train en test data </span>\n",
    "\n",
    "Om de data op te delen in train en test data kun je de volgende functie gebruiken:  \n",
    "`train_data,test_data = df.randomSplit([float1,float2])`  \n",
    "*Splits nu de data op waarbij 80% van de data train data is.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> Runnen algoritme </span>\n",
    "\n",
    "We zullen in dit labo werken met lineaire regressie. De te gebruiken functies zijn:  \n",
    "`lr = LinearRegression(labelCol = 'column_name_target', featuresCol = 'column_name_features', regParam = float)`  \n",
    "`model = lr.fit(train_data)`  \n",
    "de parameter `regParam` == lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om te testen hoe je model presteert op de test data kun je de functie `results = model.evaluate('test_data')` gebruiken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "met `results.residuals` kun je de fout die het model heeft gemaakt zien.  \n",
    "Maw hij berekent het verschil tussen de voorspelde waarde en de echte waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "met `results.r2` kan je de r-kwadraat waarde berekenen en met `results.rootMeanSquaredError` kun je de RMSE berekenen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:hotpink\"> Samenvattende oefening  </span>  \n",
    "Maak zelf een min-max scaler met de geziene functies en pas deze toe op de dataset. MAW MAAK ZELF EEN FUNCTIE NIET IMPORTEREN!!!!!  \n",
    "Resulteert dit in een betere RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

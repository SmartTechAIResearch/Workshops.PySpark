{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> PySpark labo </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens dit deel van het labo zal je de PySpark basics leren en hoe ze toe te passen voor machine learning.  \n",
    "De dataset waarmee gewerkt zal worden is data over huizen in king county en op het einde zal je de prijs van een huis proberen te voorspellen aan de hand van lineaire regressie.  \n",
    "De kolommen die aanwezig zijn in de dataset en hun beschrijving zijn:  \n",
    "`price`: prediction target  \n",
    "`bedrooms`: number of bedrooms/house  \n",
    "`bathrooms`: number of bathrooms/house  \n",
    "`sqft_living`: square footage of the home  \n",
    "`sqft_lot`: square footage of the lot  \n",
    "`floors`: Total floors(levels) in a house  \n",
    "`waterfront`: House which has a view to a waterfront  \n",
    "`view`: Has been viewed  \n",
    "`condition`: How good the condition overall is  \n",
    "`grade`: overall grade given to the housing unit, based on King County grading system  \n",
    "`sqft_above`: square footage of house apart from basement  \n",
    "`sqft_basement`: square footage of the basement  \n",
    "`yr_built`: built year  \n",
    "`yr_renovated`: Year when house was renovated  \n",
    "`zipcode`: zip  \n",
    "`sqft_living15`: Living room area in 2015(implies some renovations) This might or might not have affected the lotsize area\n",
    "`sqft_lot15`: LotSize area in 2015(implies some renovation) \n",
    "\n",
    "De te beantwoorden vragen/opdrachten staan altijd in italics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/marie/spark')\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> SparkSession, data inlezen en data weergeven</span>\n",
    "Een SparkSession voorziet een single point of entry om te interageren met de onderliggende Spark functionaliteit en laat de gebruiker toe om te programmeren met de DataFrame API.  \n",
    "De te gebruiken functie om een sparksessie te bouwen is:  \n",
    "`spark = SparkSession.builder.appName('name').getOrCreate()`  \n",
    "*Bouw nu zelf een SparkSession met de naam labo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data kan ingelezen worden met de functie: `spark.read.csv()`  \n",
    "*Laad de data kc_house_data.csv in en zet de parameters `inferSchema` en `header` op True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De functie `df.printSchema()` toont alle kolommen en het type waarden dat hierin aanwezig zijn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wat is het type waarden aanwezig in de kolom sqft_basement?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om een spark DataFrame (of spark column) weer te geven moet je de functie `df.show()` aanroepen. Dus telkens een functie een Spark Dataframe returned moet je `.show()` gebruiken om het resultaat te kunnen zien.  \n",
    "*Bekijk nu zelf de data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de namen van de kolom weer te geven als lijst kan je de functie:  \n",
    "`df.columns` gebruiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> selecteren van kolommen </span>\n",
    "Je kan een kolom selecteren aan de hand van de methode:  \n",
    "`df[\"column_name\"]`  \n",
    "Selecteer de kolom condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het verkregen type is een Column, maar met de functie `df.select('column_name')` returened een spark DataFrame, die veelzijdiger is dan het type Column.  \n",
    "*Selecteer opnieuw de kolom condition maar nu als dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de inhoud van de geselecteerde kolom weer te geven moet je de methode `.show` aanroepen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.head(n)` geeft de eerste n rijen terug als lijst.  \n",
    "Print de eerste 5 rijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan met `data.head()` ook een specifieke rij of een bepaalde waarde selecteren met behulp van:  \n",
    "`data.head(n)[row_number][column_number]`  \n",
    "*1) Selecteer de 4de rij*  \n",
    "*2) Selecteer prijs op de 3de rij*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is dit een action of transformation?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Creating a new column and dropping columns </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kan een nieuwe kolom aanmaken met de functie: `data.withColumn('new_column_name',data[\"column\"])`  \n",
    "data[\"column\"] kan ook bewerkt worden bv: `data.withColumn('new_column_name',data[\"column\"]/2)`  \n",
    "Een kolom kan verwijdert worden met `data.drop('column')`  \n",
    "_Verander nu alle sqft kolommen naar m2 (*0.0929) en verwijder de sqft kolommen._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is dit een action of transformation?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Filtering and grouping data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> Filtering Data </span>\n",
    "\n",
    "Voor het werken met big data is het belangrijk dat je snel je data kan filteren gebaseerd op bepaalde condities.  \n",
    "\n",
    "Je kunt de dataset filteren met behulp van de methode:  \n",
    "`df.filter(df[\"column_name\"] < condition)`  \n",
    "Je kan ook filteren voor meerdere condities met behulp van `|` of `&`\n",
    "\n",
    "*Filter de dataset voor huizen die gebouwd zijn na het jaar 2000, sla dit op onder de variabele `data_2000`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de `.count()` methode kan je het aantal gefilterde huizen opvragen.  \n",
    "*Hoeveel huizen bevat `dataset_2000` met minimum 2 slaapkamers en die gelegen zijn aan het waterfront?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> GroupBy and Aggregate Functions </span>\n",
    "\n",
    "De `groupBy('column_name')` functie laat je rijen groeperen gebaseerd op een bepaalde kolom, bijvoorbeeld je kan huizen groeperen volgens bouwjaar.  \n",
    "Eenmaal je de rijen gegroepeerd hebt, kan je meerdere rijen van data aggregeren tot een output, bijvoorbeeld door het nemen van de som van alle inputrijen of de minimum waarde.  \n",
    "*Gebruik de groupBy functie op de 'condition' kolom en vraag de minimum waarde op met de .min() functie.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Groepeer de rijen volgens de `waterfront` kolom en aggregeer volgens het gemiddelde.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niet alle methoden hebben nood aan een groupby call. In plaats darvan kan je de algemene agg() methode oproepen. \n",
    "Dit kan alle rijen in de dataframe aggregeren in een kolom.  \n",
    "`df.agg({'column_name':'operation'})` de operation kan mean,min,max,count en sum zijn.\n",
    "\n",
    "*Gebruik de algemene agg() methode om de gemiddelde prijs te vinden*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze functie geeft echter een DataFrame terug, wat niet zo handig is bv. als je het gemiddelde nodig hebt om berekeningen uit te voeren. Om enkel het getal terug te krijgen moet je het getal als volgt uit de spark DataFrame halen:  \n",
    "`[row_number][column_number]`  \n",
    "*Zorg ervoor dat de algemene agg() methode het gemiddelde als getal terug geeft.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Groepeer eerst alle rijen volgens `yr_renovated` en sla dit op als de variabele `grouped`. \n",
    "Gebruik vervolgens de algemene agg() methode om de maximale prijs te vinden per jaar*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Machine learning with PySpark </span>\n",
    "\n",
    "Om machine learning te kunnen toepassen met MlLib verwacht spark een format dat 2 kolommen bevat met de namen: \"label\" en \"features\".  \n",
    "De label kolom moet een numerische label bevatten, dit kan een numerische waarde zijn voor regressie of classificatie.  \n",
    "De feature kolom moet een vector van alle features bevatten.  \n",
    "In deze sectie zal je een dataframe omzetten naar het verwachte format en zal je de huisprijzen proberen te voorspellen met lineaire regressie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:hotpink\"> Prepping the data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> Prepping the data </span>\n",
    "Om de data correct voor te bereiden moeten alle features in een kolom onder de vorm van een vector aanwezig zijn.\n",
    "Dit kan bereikt worden met de functies: `assembler = VectorAssembler(inputCols=[list_of_column_names],outputCol='features')`  \n",
    "`new_dataframe = assembler.transform(df)`  \n",
    "*Maak een lijst met alle kolomnamen die gebruikt kunnen worden als features en transformeer ze met de VectorAssembler.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> Splitsen in train en test data </span>\n",
    "\n",
    "Om de data op te delen in train en test data kun je de volgende functie gebruiken:  \n",
    "`train_data,test_data = df.randomSplit([float1,float2])`  \n",
    "*Splits nu de data op waarbij 80% van de data train data is.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:hotpink\"> Runnen algoritme </span>\n",
    "\n",
    "We zullen in dit labo werken met lineaire regressie. De te gebruiken functies zijn:  \n",
    "`lr = LinearRegression(labelCol = 'column_name_target', featuresCol = 'column_name_features, regParam = float)`  \n",
    "`model = lr.fit(train_data)`  \n",
    "de parameter `regParam` == lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extra oefening: maak zelf een min-max scaler met de geziene functies en pas deze toe op de dataset. Resulteert dit in een betere MSE?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
